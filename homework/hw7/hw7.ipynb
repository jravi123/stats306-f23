{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "1SPCENz_KDM-",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d1761bfdb43c7ec3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "44f838f3-456e-4881-b239-cde6de7a1b2d",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "Downloading GitHub repo bradleyboehmke/harrypotter@HEAD\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m──\u001b[39m \u001b[36mR CMD build\u001b[39m \u001b[36m─────────────────────────────────────────────────────────────────\u001b[39m\n",
      "* checking for file ‘/tmp/RtmpZgwcFA/remotes11b6cbd5977/bradleyboehmke-harrypotter-51f7146/DESCRIPTION’ ... OK\n",
      "* preparing ‘harrypotter’:\n",
      "* checking DESCRIPTION meta-information ... OK\n",
      "* checking for LF line-endings in source and make files and shell scripts\n",
      "* checking for empty or unneeded directories\n",
      "* building ‘harrypotter_0.1.0.tar.gz’\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "also installing the dependencies ‘Rcpp’, ‘SnowballC’, ‘janeaustenr’, ‘tokenizers’\n",
      "\n",
      "\n",
      "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdplyr    \u001b[39m 1.1.3     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2  \u001b[39m 3.4.3     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.2.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.3     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.0.2     \n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"tidyverse\")\n",
    "remotes::install_github(\"bradleyboehmke/harrypotter\")\n",
    "install.packages(\"tidytext\")\n",
    "library(tidyverse)\n",
    "library(stringr)\n",
    "options(jupyter.rich_display=T)\n",
    "library(harrypotter)\n",
    "library(tidytext)\n",
    "options(repr.plot.width=4, repr.plot.height=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "i8VBJe1DLrKG",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# STATS 306\n",
    "## Homework 7: Text Analysis\n",
    "\n",
    "For each problem, enter the R code in the cell marked \"YOUR SOLUTION HERE\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7E7UUJ0eZuA"
   },
   "source": [
    "**Important: Please read all the points below before attempting the problems.**\n",
    "\n",
    "1. The file `afinn.RData` contains a sentiment score for a large number of words in the English language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "UDboQC3-eTfz",
    "outputId": "79f3d9cd-2d39-4721-b3bf-5a8a5073fffe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>word</th><th scope=col>value</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>abandon   </td><td>-2</td></tr>\n",
       "\t<tr><td>abandoned </td><td>-2</td></tr>\n",
       "\t<tr><td>abandons  </td><td>-2</td></tr>\n",
       "\t<tr><td>abducted  </td><td>-2</td></tr>\n",
       "\t<tr><td>abduction </td><td>-2</td></tr>\n",
       "\t<tr><td>abductions</td><td>-2</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 2\n",
       "\\begin{tabular}{ll}\n",
       " word & value\\\\\n",
       " <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t abandon    & -2\\\\\n",
       "\t abandoned  & -2\\\\\n",
       "\t abandons   & -2\\\\\n",
       "\t abducted   & -2\\\\\n",
       "\t abduction  & -2\\\\\n",
       "\t abductions & -2\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 2\n",
       "\n",
       "| word &lt;chr&gt; | value &lt;dbl&gt; |\n",
       "|---|---|\n",
       "| abandon    | -2 |\n",
       "| abandoned  | -2 |\n",
       "| abandons   | -2 |\n",
       "| abducted   | -2 |\n",
       "| abduction  | -2 |\n",
       "| abductions | -2 |\n",
       "\n"
      ],
      "text/plain": [
       "  word       value\n",
       "1 abandon    -2   \n",
       "2 abandoned  -2   \n",
       "3 abandons   -2   \n",
       "4 abducted   -2   \n",
       "5 abduction  -2   \n",
       "6 abductions -2   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load(url(\"https://datasets.stats306.org/afinn.RData\"))\n",
    "head(afinn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5w5mLKMepg9"
   },
   "source": [
    "Negatively connoted words receive low scores, while positively connoted words receive high scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "ogAHsMgFeTkx",
    "outputId": "94367f3e-db12-4f81-ae9b-8813718b84e7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A spec_tbl_df: 4 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>word</th><th scope=col>value</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>angry    </td><td>-3</td></tr>\n",
       "\t<tr><td>happy    </td><td> 3</td></tr>\n",
       "\t<tr><td>sad      </td><td>-2</td></tr>\n",
       "\t<tr><td>wonderful</td><td> 4</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A spec\\_tbl\\_df: 4 × 2\n",
       "\\begin{tabular}{ll}\n",
       " word & value\\\\\n",
       " <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t angry     & -3\\\\\n",
       "\t happy     &  3\\\\\n",
       "\t sad       & -2\\\\\n",
       "\t wonderful &  4\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A spec_tbl_df: 4 × 2\n",
       "\n",
       "| word &lt;chr&gt; | value &lt;dbl&gt; |\n",
       "|---|---|\n",
       "| angry     | -3 |\n",
       "| happy     |  3 |\n",
       "| sad       | -2 |\n",
       "| wonderful |  4 |\n",
       "\n"
      ],
      "text/plain": [
       "  word      value\n",
       "1 angry     -3   \n",
       "2 happy      3   \n",
       "3 sad       -2   \n",
       "4 wonderful  4   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter(afinn, word %in% c(\"angry\", \"sad\", \"happy\", \"wonderful\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_Rw3n3Teupm"
   },
   "source": [
    "2. The `tidytext::unnest_tokens()` function can be used to break a chunk of text into \"tokens\" (e.g., words, sentences). It works as follows. Consider the following tibble, which contains all 19 chapters of the second book in the Harry Potter series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9JOPYkDieTm1",
    "outputId": "3315d05f-580b-4024-8b31-c9a89e3f30f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 19 × 2\u001b[39m\n",
      "   chapter text                                                                 \n",
      "     \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                                                \n",
      "\u001b[90m 1\u001b[39m       1 \u001b[90m\"\u001b[39mTHE WORST BIRTHDAY　　Not for the first time, an argument had broke…\n",
      "\u001b[90m 2\u001b[39m       2 \u001b[90m\"\u001b[39m　　DOBBY'S WARNING　　arry managed not to shout out, but it was a …\n",
      "\u001b[90m 3\u001b[39m       3 \u001b[90m\"\u001b[39mTHE BURROW　　Ron.l\\\" breathed Harry, creeping to the window and pu…\n",
      "\u001b[90m 4\u001b[39m       4 \u001b[90m\"\u001b[39mAT FL0VRR 11 $ HAND BLOTTS　　ife at the Burrow was as different as…\n",
      "\u001b[90m 5\u001b[39m       5 \u001b[90m\"\u001b[39mTHE WHOMPING　　WILLOW　　he end of the summer vacation came too qu…\n",
      "\u001b[90m 6\u001b[39m       6 \u001b[90m\"\u001b[39mGILDEROY LOCKHART　　he next day, however, Harry barely grinned onc…\n",
      "\u001b[90m 7\u001b[39m       7 \u001b[90m\"\u001b[39mHarry looked bemusedly at the photograph Colin was brandishing unde…\n",
      "\u001b[90m 8\u001b[39m       8 \u001b[90m\"\u001b[39m　　\\\"What are you talking about, Harry? Perhaps you're getting a l…\n",
      "\u001b[90m 9\u001b[39m       9 \u001b[90m\"\u001b[39mTHE WRTITING ON THE WALL　　What's going on here? What's going on?\\…\n",
      "\u001b[90m10\u001b[39m      10 \u001b[90m\"\u001b[39m　　THE ROGUE BLUDGER　　ince the disastrous episode of the pixies,…\n",
      "\u001b[90m11\u001b[39m      11 \u001b[90m\"\u001b[39m　　THE D-KJEL]ING C-L-IJIB　　Harry woke up on Sunday morning to f…\n",
      "\u001b[90m12\u001b[39m      12 \u001b[90m\"\u001b[39m　　THE POLYJUICE POTION　　hey stepped off the stone staircase at …\n",
      "\u001b[90m13\u001b[39m      13 \u001b[90m\"\u001b[39m　　Malfoy started taking pictures with an imaginary camera and did…\n",
      "\u001b[90m14\u001b[39m      14 \u001b[90m\"\u001b[39mstill, heart-shaped confetti was falling from the pale blue ceiling…\n",
      "\u001b[90m15\u001b[39m      15 \u001b[90m\"\u001b[39mDippet sank back, looking faintly disappointed.　　\\\"You may go, To…\n",
      "\u001b[90m16\u001b[39m      16 \u001b[90m\"\u001b[39m　　\\\"The appointment - or suspension - of the headmaster is a matt…\n",
      "\u001b[90m17\u001b[39m      17 \u001b[90m\"\u001b[39mstood, terrified, waiting. There was a strange rumbling noise and t…\n",
      "\u001b[90m18\u001b[39m      18 \u001b[90m\"\u001b[39m　　\\\"Right,\\\" said Professor McGonagall, whose nostrils were flare…\n",
      "\u001b[90m19\u001b[39m      19 \u001b[90m\"\u001b[39m　　\\\"What d'you mean, I won't be -?\\\"　　\\\"I've waited a long time…\n"
     ]
    }
   ],
   "source": [
    "chamber_tbl <- tibble(chapter = seq_along(chamber_of_secrets),\n",
    "                   text = chamber_of_secrets) %>% print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y97dPBv5fNQe"
   },
   "source": [
    "To perform sentiment analysis, we need to break each chapter into words so that we can join it to the `afinn` table. This is what `unnest_tokens()` does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4aACeisfEVp",
    "outputId": "57577ef8-681a-4687-f7bb-736987bf0134"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 85,401 × 2\u001b[39m\n",
      "   chapter word    \n",
      "     \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m   \n",
      "\u001b[90m 1\u001b[39m       1 the     \n",
      "\u001b[90m 2\u001b[39m       1 worst   \n",
      "\u001b[90m 3\u001b[39m       1 birthday\n",
      "\u001b[90m 4\u001b[39m       1 not     \n",
      "\u001b[90m 5\u001b[39m       1 for     \n",
      "\u001b[90m 6\u001b[39m       1 the     \n",
      "\u001b[90m 7\u001b[39m       1 first   \n",
      "\u001b[90m 8\u001b[39m       1 time    \n",
      "\u001b[90m 9\u001b[39m       1 an      \n",
      "\u001b[90m10\u001b[39m       1 argument\n",
      "\u001b[90m# ℹ 85,391 more rows\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "chamber_tok <- unnest_tokens(chamber_tbl, input = text, output = word) %>% print # break sentences into words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQ-RRsWXfVup"
   },
   "source": [
    "3. Unless specified otherwise, all matches are case insensitive.\n",
    "\n",
    "4. Follow https://piazza.com/class/llmfic6yndcf1/post/247 on how to load .csv file into Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFHTgGolMyHd"
   },
   "source": [
    "## Problem 1: Taylor Swift Song Lyrics (4 points)\n",
    "\n",
    "Upload the file `TaylorSwift.csv` into Google Colab and run the code below. The variable `taylor_swift` contains information about all 140 of Taylor Swift's songs in her studio albums \"Taylor Swift\", \"Fearless\", \"Speak Now\", \"Red (Deluxe Edition)\", \"1989\", \"reputation\", \"Lover\", \"folklore\", and \"evermore\".\n",
    "\n",
    "Please run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gzECXEs5MxYU",
    "outputId": "e053c733-b1bd-48de-c5cc-228e7486a2fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 140\n",
      "Columns: 6\n",
      "$ Artist \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Taylor Swift\", \"Taylor Swift\", \"Taylor Swift\", \"Taylor Swift\",…\n",
      "$ Title  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"​cardigan\", \"​exile\", \"Lover\", \"​the 1\", \"Look What You Made Me D…\n",
      "$ Album  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"folklore\", \"folklore\", \"Lover\", \"folklore\", \"reputation\", \"fol…\n",
      "$ Year   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 2020, 2020, 2019, 2020, 2017, 2020, 2017, 2019, 2019, 2020, 201…\n",
      "$ Date   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"2020-07-24\", \"2020-07-24\", \"2019-08-16\", \"2020-07-24\", \"2017-0…\n",
      "$ Lyric  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"vintage tee brand new phone high heels on cobblestones when yo…\n"
     ]
    }
   ],
   "source": [
    "studio_albums <- c(\"Taylor Swift\", \"Fearless\", \"Speak Now\", \"Red (Deluxe Edition)\",\n",
    "                   \"1989\", \"reputation\", \"Lover\", \"folklore\", \"evermore\")\n",
    "\n",
    "taylor_swift <- read.csv(\"TaylorSwift.csv\") %>%\n",
    "  subset(select = -X) %>%\n",
    "  filter(Album %in% studio_albums) %>%\n",
    "  filter(Title != \"Reputation Magazine Vol. 1\")\n",
    "\n",
    "glimpse(taylor_swift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bh9jEv6-Nt10"
   },
   "source": [
    "(a) Define the *sentiment score* of a song as the average sentiment value of all words in its lyric (based on the `afinn` data set). For simplicity, assume that the sentiment value of a word that does not exist in the `afinn` data set is $0$.\n",
    "\n",
    "Let's consider a concrete example. Suppose we have the following song lyric: \"*i love you i adore you i am waiting for you*\". Using the above definition, its sentiment score is $6/11 \\approx 0.545$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "Fg92AOZzMxdf",
    "outputId": "2678a882-1169-4907-f23e-c601737fa953"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A spec_tbl_df: 2 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>word</th><th scope=col>value</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>adore</td><td>3</td></tr>\n",
       "\t<tr><td>love </td><td>3</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A spec\\_tbl\\_df: 2 × 2\n",
       "\\begin{tabular}{ll}\n",
       " word & value\\\\\n",
       " <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t adore & 3\\\\\n",
       "\t love  & 3\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A spec_tbl_df: 2 × 2\n",
       "\n",
       "| word &lt;chr&gt; | value &lt;dbl&gt; |\n",
       "|---|---|\n",
       "| adore | 3 |\n",
       "| love  | 3 |\n",
       "\n"
      ],
      "text/plain": [
       "  word  value\n",
       "1 adore 3    \n",
       "2 love  3    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "afinn %>%\n",
    "  filter(word %in% c(\"i\", \"love\", \"you\", \"adore\", \"am\", \"waiting\", \"for\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-9s0z2iNzI4"
   },
   "source": [
    "Which songs have the highest and lowest sentiment scores? What are the sentiment scores of these songs, rounded to 3 decimal places? Use the `tidytext::unnest_tokens()` function **(0.75 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QF0EEAjlMk2-"
   },
   "outputs": [],
   "source": [
    "### YOUR SOLUTION HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LKb4z2gOmzC"
   },
   "source": [
    "(b) Define the sentiment score of an album as the average sentiment score of all songs in that album. Produce a table containing the average sentiment score of each album, rounded to 3 decimal places. Order the rows in descending order of sentiment score. Again, use the `tidytext::unnest_tokens()` function. **(0.75 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tq6havqNOpiR"
   },
   "outputs": [],
   "source": [
    "### YOUR SOLUTION HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z62qoS4NOBiP"
   },
   "source": [
    "(c) *n-gram* is defined as a series of $n$ adjacent words on a text. For example, in the example lyric above, all the $2$-grams (also referred to as bigrams) are \"*i love*\", \"*love you*\", \"*you i*\", \"*i adore*\", \"*adore you*\", \"*you i*\", \"*i am*\", \"*am waitin'*\", \"*waitin' for*\", and \"*for you*\".\n",
    "\n",
    "Display a table consisting of the most common bigrams in each album. This table should contain 3 columns: `Album`, `Bigram`, and `n`. Sort your table in descending order of `n`. Again, use the `tidytext::unnest_tokens()` function. **(0.75 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QSXCQq-ROBIc"
   },
   "outputs": [],
   "source": [
    "### YOUR SOLUTION HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zh69l98qOMTC"
   },
   "source": [
    "(d) Define the *repetitiveness score* of a song to be *one minus* the number of unique words in its lyrics divided by the number of words. For instance, if a song's lyric consists of all distinct words, its repetitiveness score is $0$. On the other hand, if a song's lyric consists of just a single word, its repetitiveness score is $\\frac{n-1}{n}$, where $n$ is the number of words in the song's lyric.\n",
    "\n",
    "What is the average (mean) repetitiveness score of all songs in the data set? Again, use the `tidytext::unnest_tokens()` function.\n",
    "\n",
    "Also, graphically display the distribution of the repetitiveness scores of all songs in the data set. Comment on the shape of the distribution. **(0.75 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ab1B2N3cMlCs"
   },
   "outputs": [],
   "source": [
    "### YOUR SOLUTION HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5wzLwuNOUdu"
   },
   "source": [
    "(e) **For this question, use the `str_split()` function.**\n",
    "\n",
    "Find the 5 most common words that *start* with a `'` (e.g., `'cause`), as well as their frequencies. Repeat the same exercise for:\n",
    "\n",
    "i. Words that *end* with a `'` (e.g., `standin'`); and\n",
    "\n",
    "ii. Words that *contain* `'` in the *middle* (*not in the first or last position*; e.g., `i'd`). **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lkGf4ofCOPl9"
   },
   "outputs": [],
   "source": [
    "### YOUR SOLUTION HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Yp7WT7I1KDNF",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2be6421ceea97f78",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Problem 2: Sentiment Analysis on Harry Potter Books (4 points)\n",
    "\n",
    "In Problem 2, we will perform *sentiment analysis* of the Harry Potter books."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "kPM1RnIKKDNH",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f434554a9cb77230",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "(a) By joining `chamber_tok` (defined above) to another table containing text data and summarizing, we can generate scores of how positive or negative the text is. Concretely, using `chamber_tok` and `afinn`, we can assign sentiment scores to various portions of text. Unlike in Problem 1, ignore words that do not exist in `afinn` when calculating sentiment scores. For example, the sentiment score of \"*i love you i adore you i am waiting for you*\" is now $3$ instead of $6/11$.\n",
    "\n",
    "Generate a plot reflecting how the sentiment changes over 19 chapters of the second book in the Harry Potter series. What conclusion can you draw from the plot? **(1.5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MnG3nbbBY8ps",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR SOLUTION HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "-YSgb5cqKDNH",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-764bdd8bbd4ec469",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "(b) Perform sentiment analysis to all 7 books in Harry Potter series, and report a table with each book's average sentiment score. Create a bar plot for each book's average sentiment score from highest to lowest. Which book is the most positive and which book is the darkest? **(1.5 points)**\n",
    "\n",
    "**HINT**: Run the following code to obtain a list of all the Harry Potter books under the `harrypotter` package. You may use `coord_flip()` to avoid overlapping on the x-axis if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xRG66yt_2U1j"
   },
   "outputs": [],
   "source": [
    "# run for understanding if needed\n",
    "# help(package = \"harrypotter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uxRtDoIP2d48",
    "outputId": "6d9a9758-6294-4572-da8d-67e17bb37410"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 200 × 3\u001b[39m\n",
      "   chapter text                                                            book \n",
      "     \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                                           \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m       1 \u001b[90m\"\u001b[39mTHE BOY WHO LIVED　　Mr. and Mrs. Dursley, of number four, Pr… Phil…\n",
      "\u001b[90m 2\u001b[39m       2 \u001b[90m\"\u001b[39mTHE VANISHING GLASS　　Nearly ten years had passed since the … Phil…\n",
      "\u001b[90m 3\u001b[39m       3 \u001b[90m\"\u001b[39mTHE LETTERS FROM NO ONE　　The escape of the Brazilian boa co… Phil…\n",
      "\u001b[90m 4\u001b[39m       4 \u001b[90m\"\u001b[39mTHE KEEPER OF THE KEYS　　BOOM. They knocked again. Dudley je… Phil…\n",
      "\u001b[90m 5\u001b[39m       5 \u001b[90m\"\u001b[39mDIAGON ALLEY　　Harry woke early the next morning. Although h… Phil…\n",
      "\u001b[90m 6\u001b[39m       6 \u001b[90m\"\u001b[39mTHE JOURNEY FROM PLATFORM NINE AND THREE-QUARTERS　　Harry's … Phil…\n",
      "\u001b[90m 7\u001b[39m       7 \u001b[90m\"\u001b[39mTHE SORTING HAT　　The door swung open at once. A tall, black… Phil…\n",
      "\u001b[90m 8\u001b[39m       8 \u001b[90m\"\u001b[39mTHE POTIONS MASTER　　There, look.\\\"　　\\\"Where?\\\"　　\\\"Next … Phil…\n",
      "\u001b[90m 9\u001b[39m       9 \u001b[90m\"\u001b[39mTHE MIDNIGHT DUEL　　Harry had never believed he would meet a… Phil…\n",
      "\u001b[90m10\u001b[39m      10 \u001b[90m\"\u001b[39mHALLOWEEN　　Malfoy couldn't believe his eyes when he saw tha… Phil…\n",
      "\u001b[90m# ℹ 190 more rows\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "phil_tbl <- tibble(chapter = seq_along(philosophers_stone),\n",
    "                   text = philosophers_stone)\n",
    "prisoner_tbl <- tibble(chapter = seq_along(prisoner_of_azkaban),\n",
    "                   text = prisoner_of_azkaban)\n",
    "goblet_tbl <- tibble(chapter = seq_along(goblet_of_fire),\n",
    "                   text = goblet_of_fire)\n",
    "phoenix_tbl <- tibble(chapter = seq_along(order_of_the_phoenix),\n",
    "                   text = order_of_the_phoenix)\n",
    "prince_tbl <- tibble(chapter = seq_along(half_blood_prince),\n",
    "                   text = half_blood_prince)\n",
    "hallows_tbl <- tibble(chapter = seq_along(deathly_hallows),\n",
    "                   text = deathly_hallows)\n",
    "\n",
    "all_books <- bind_rows(\n",
    "  phil_tbl %>% mutate(book = \"Philosopher's Stone\"),\n",
    "  chamber_tbl %>% mutate(book = 'Chamber of Secrets'),\n",
    "  prisoner_tbl %>% mutate(book = \"Prisoner of Azkaban\"),\n",
    "  goblet_tbl %>% mutate(book = \"Goblet of Fire\"),\n",
    "  phoenix_tbl %>% mutate(book = \"Order of the Phoenix\"),\n",
    "  prince_tbl %>% mutate(book = \"Half-Blood Prince\"),\n",
    "  hallows_tbl %>% mutate(book = \"Deathly Hallows\")\n",
    ") %>% print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "zG0a47uR3-Xq",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## YOUR SOLUTION HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": true,
    "id": "aqZmeQx9hHVl",
    "run_control": {
     "frozen": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(c) Print out the words across any of the books that have a sentiment score of 5. **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "id": "8TW5woyxA5T4",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## YOUR SOLUTION HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_DTj2_MG0dDA"
   },
   "source": [
    "## Challenge Problem: Text Ranking (2 points)\n",
    "Not all terms/words are equally important, and some carry more information about contents. But how do we measure the importance? One popular method is using TF-IDF (term frequency–inverse document frequency). TF-IDF is a numerical statistic that is intended to reflect how important a word is to a document in a collection. Term Frequency measures the relative frequency of term within document. Inverse Document Frequency measures of how much information the word provides for the collection.\n",
    "\n",
    "We defined TF-IDF as:\n",
    "\n",
    "$$\\text{TF-IDF} = \\operatorname{TF}(t,d) \\times \\operatorname{IDF}(t)$$\n",
    "$$\\operatorname{TF}(t, d) = 1 + \\log(c(t,d))$$\n",
    "$$\\operatorname{IDF}(t) = \\log(N/k)$$\n",
    "\n",
    "where $c(t,d)$ is the frequency count of term $t$ in document $d$, $N$ is the total number of documents in the collection, $k$ is the number\n",
    "of documents containing term $t$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "hZu4hDN843rC",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "Consider the Harry Potter series as a collection of documents (books). Find the top 5 words in each book ranked by TF-IDF. *Show your result as a table* with at least book name, word, and the corresponding TF-IDF score as columns. **(2 points)**\n",
    "\n",
    "**HINT:** Think about how to calculate TF-IDF scores with the formulas provided above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HTWS1entHgjD"
   },
   "outputs": [],
   "source": [
    "## YOUR SOLUTION HERE\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
